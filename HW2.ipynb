{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-14T12:53:17.787564Z","iopub.execute_input":"2021-11-14T12:53:17.787916Z","iopub.status.idle":"2021-11-14T12:53:17.803441Z","shell.execute_reply.started":"2021-11-14T12:53:17.787861Z","shell.execute_reply":"2021-11-14T12:53:17.802677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint('Loading data ...')\n\ndata_root='/kaggle/input/ml2021springhw2/timit_11/timit_11/'\ntrain = np.load(data_root + 'train_11.npy')\ntrain_label = np.load(data_root + 'train_label_11.npy')\ntest = np.load(data_root + 'test_11.npy')\n\nprint('Size of training data: {}'.format(train.shape))\nprint('Size of testing data: {}'.format(test.shape))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:17.805126Z","iopub.execute_input":"2021-11-14T12:53:17.805535Z","iopub.status.idle":"2021-11-14T12:53:55.440063Z","shell.execute_reply.started":"2021-11-14T12:53:17.805496Z","shell.execute_reply":"2021-11-14T12:53:55.437827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create Dataset**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass TIMITDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = torch.from_numpy(X).float()\n        if y is not None:\n            y = y.astype(np.int)\n            self.label = torch.LongTensor(y)\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:55.441575Z","iopub.execute_input":"2021-11-14T12:53:55.441836Z","iopub.status.idle":"2021-11-14T12:53:55.449065Z","shell.execute_reply.started":"2021-11-14T12:53:55.441803Z","shell.execute_reply":"2021-11-14T12:53:55.448369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split the labeled data into a training set and a validation set, you can modify the variable VAL_RATIO to change the ratio of validation data.","metadata":{}},{"cell_type":"code","source":"VAL_RATIO = 0.2\n\npercent = int(train.shape[0] * (1 - VAL_RATIO))\ntrain_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\nprint('Size of training set: {}'.format(train_x.shape))\nprint('Size of validation set: {}'.format(val_x.shape))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:55.450764Z","iopub.execute_input":"2021-11-14T12:53:55.451388Z","iopub.status.idle":"2021-11-14T12:53:55.464264Z","shell.execute_reply.started":"2021-11-14T12:53:55.451352Z","shell.execute_reply":"2021-11-14T12:53:55.46334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a data loader from the dataset, feel free to tweak the variable `BATCH_SIZE` here.","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 128\n\nfrom torch.utils.data import DataLoader\n\ntrain_set = TIMITDataset(train_x, train_y)\nval_set = TIMITDataset(val_x, val_y)\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\nval_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:55.467497Z","iopub.execute_input":"2021-11-14T12:53:55.467856Z","iopub.status.idle":"2021-11-14T12:53:57.692067Z","shell.execute_reply.started":"2021-11-14T12:53:55.467821Z","shell.execute_reply":"2021-11-14T12:53:57.691344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cleanup the unneeded variables to save memory.\n\nnotes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later\nthe data size is quite huge, so be aware of memory usage in colab","metadata":{}},{"cell_type":"code","source":"import gc\n\ndel train, train_label, train_x, train_y, val_x, val_y\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:57.693551Z","iopub.execute_input":"2021-11-14T12:53:57.693804Z","iopub.status.idle":"2021-11-14T12:53:57.859254Z","shell.execute_reply.started":"2021-11-14T12:53:57.693772Z","shell.execute_reply":"2021-11-14T12:53:57.858566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create Model**","metadata":{}},{"cell_type":"markdown","source":"Define model architecture, you are encouraged to change and experiment with the model architecture.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        self.layer1 = nn.Linear(429, 2048)\n        self.layer2 = nn.Linear(2048, 2048)\n        self.layer3 = nn.Linear(2048, 1024)\n        self.layer4 = nn.Linear(1024, 512)\n        self.layer5 = nn.Linear(512, 128)\n        \n        \n        self.out = nn.Linear(128, 39) \n        \n        self.bn1 = nn.BatchNorm1d(2048)\n        self.bn2 = nn.BatchNorm1d(2048)\n        self.bn3 = nn.BatchNorm1d(1024)\n        self.bn4 = nn.BatchNorm1d(512)\n        self.bn5 = nn.BatchNorm1d(128)\n        \n        self.drop = nn.Dropout(0.2)\n        \n        self.act_fn = nn.ReLU()\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.bn1(x)\n        x = self.act_fn(x)\n        x = self.drop(x)\n\n        x = self.layer2(x)\n        x = self.bn2(x)\n        x = self.act_fn(x)\n        x = self.drop(x)\n\n\n        x = self.layer3(x)\n        x = self.bn3(x)\n        x = self.act_fn(x)\n        x = self.drop(x)\n        \n        x = self.layer4(x)\n        x = self.bn4(x)\n        x = self.act_fn(x)\n        x = self.drop(x)\n        \n        x = self.layer5(x)\n        x = self.bn5(x)\n        x = self.act_fn(x)\n        x = self.drop(x)\n\n\n        x = self.out(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:57.86052Z","iopub.execute_input":"2021-11-14T12:53:57.860919Z","iopub.status.idle":"2021-11-14T12:53:57.869947Z","shell.execute_reply.started":"2021-11-14T12:53:57.860882Z","shell.execute_reply":"2021-11-14T12:53:57.869274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"#check device\ndef get_device():\n  return 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:57.871223Z","iopub.execute_input":"2021-11-14T12:53:57.871577Z","iopub.status.idle":"2021-11-14T12:53:57.879525Z","shell.execute_reply.started":"2021-11-14T12:53:57.871538Z","shell.execute_reply":"2021-11-14T12:53:57.878768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix random seed\ndef same_seeds(seed):\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)  \n    np.random.seed(seed)  \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:57.881357Z","iopub.execute_input":"2021-11-14T12:53:57.881671Z","iopub.status.idle":"2021-11-14T12:53:57.88885Z","shell.execute_reply.started":"2021-11-14T12:53:57.881633Z","shell.execute_reply":"2021-11-14T12:53:57.888026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feel free to change the training parameters here.","metadata":{}},{"cell_type":"code","source":"# fix random seed for reproducibility\nsame_seeds(0)\n\n# get device \ndevice = get_device()\nprint(f'DEVICE: {device}')\n\n# training parameters\nnum_epoch = 20               # number of training epoch\nlearning_rate = 0.0001       # learning rate\n\n# the path where checkpoint saved\nmodel_path = './model.ckpt'\n\n# create model, define a loss function, and optimizer\nmodel = Classifier().to(device)\ncriterion = nn.CrossEntropyLoss() \noptimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:57.890245Z","iopub.execute_input":"2021-11-14T12:53:57.891221Z","iopub.status.idle":"2021-11-14T12:53:57.914445Z","shell.execute_reply.started":"2021-11-14T12:53:57.891187Z","shell.execute_reply":"2021-11-14T12:53:57.913681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# start training\n\nbest_acc = 0.0\nfor epoch in range(num_epoch):\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n\n    # training\n    model.train() # set the model to training mode\n    for i, data in enumerate(train_loader):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad() \n        outputs = model(inputs) \n        batch_loss = criterion(outputs, labels)\n        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n        \n        batch_loss.backward() \n        optimizer.step() \n\n        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n        train_loss += batch_loss.item()\n\n    # validation\n    if len(val_set) > 0:\n        model.eval() # set the model to evaluation mode\n        with torch.no_grad():\n            for i, data in enumerate(val_loader):\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                batch_loss = criterion(outputs, labels) \n                _, val_pred = torch.max(outputs, 1) \n            \n                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n                val_loss += batch_loss.item()\n\n            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n            ))\n\n            # if the model improves, save a checkpoint at this epoch\n            if val_acc > best_acc:\n                best_acc = val_acc\n                torch.save(model.state_dict(), model_path)\n                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n    else:\n        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n        ))\n\n# if not validating, save the last epoch\nif len(val_set) == 0:\n    torch.save(model.state_dict(), model_path)\n    print('saving model at last epoch')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:53:57.915961Z","iopub.execute_input":"2021-11-14T12:53:57.916491Z","iopub.status.idle":"2021-11-14T13:08:23.25503Z","shell.execute_reply.started":"2021-11-14T12:53:57.916452Z","shell.execute_reply":"2021-11-14T13:08:23.254243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"markdown","source":"Create a testing dataset, and load model from the saved checkpoint.","metadata":{}},{"cell_type":"code","source":"# create testing dataset\ntest_set = TIMITDataset(test, None)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n\n# create model and load weights from checkpoint\nmodel = Classifier().to(device)\nmodel.load_state_dict(torch.load(model_path))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T13:08:23.256544Z","iopub.execute_input":"2021-11-14T13:08:23.257049Z","iopub.status.idle":"2021-11-14T13:08:23.842181Z","shell.execute_reply.started":"2021-11-14T13:08:23.257012Z","shell.execute_reply":"2021-11-14T13:08:23.841501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make prediction.","metadata":{}},{"cell_type":"code","source":"predict = []\nmodel.eval() # set the model to evaluation mode\nwith torch.no_grad():\n    for i, data in enumerate(test_loader):\n        inputs = data\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n\n        for y in test_pred.cpu().numpy():\n            predict.append(y)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T13:08:23.84344Z","iopub.execute_input":"2021-11-14T13:08:23.843958Z","iopub.status.idle":"2021-11-14T13:08:28.245323Z","shell.execute_reply.started":"2021-11-14T13:08:23.843916Z","shell.execute_reply":"2021-11-14T13:08:28.244591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write prediction to a CSV file.\n\nAfter finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle.","metadata":{}},{"cell_type":"code","source":"with open('prediction.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(predict):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T13:08:28.247825Z","iopub.execute_input":"2021-11-14T13:08:28.248195Z","iopub.status.idle":"2021-11-14T13:08:28.645614Z","shell.execute_reply.started":"2021-11-14T13:08:28.248156Z","shell.execute_reply":"2021-11-14T13:08:28.644702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}